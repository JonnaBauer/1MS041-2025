{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 4th of January 2024, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"XXX\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_inversion` in order to produce samples from the below distribution using rejection sampling:\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-1}{e-1}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "2. [2p] Produce 100000 samples (**use fewer if it times-out and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. *(There is a timeout decorator on this function and if it takes more than 10 seconds to generate 100000 samples it will timeout and it will count as if you failed to generate.)*\n",
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2e^{x^2} x}{e-1} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n",
    "\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n",
    "\n",
    "5. [4p] Fill in the remaining part of the function `problem1_inversion_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59830875 0.66723745 0.6974535  0.73392816 0.8547419  0.93198836\n",
      " 0.28238271 0.61682898 0.48276159 0.83848265]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 1\n",
    "\n",
    "import scipy\n",
    "from Utils import timeout\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "#@timeout\n",
    "def problem1_inversion(n_samples=1):\n",
    "    # Distribution from part 1\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "\n",
    "    # Return a numpy array of length n_samples\n",
    "    \n",
    "    def f(x): # Target density (the derivative of F(x))\n",
    "        if x <= 0 or x >= 1:\n",
    "            return 0\n",
    "        else:\n",
    "            # e^(x^2)-1/(e - 1) = e^(x^2)/(e - 1) - 1/(e - 1)\n",
    "            #Deriverar med hj채lp av kedjeregeln och f책r\n",
    "            # 2xe^(x^2)/(e - 1)\n",
    "            return 2*x*np.exp(x**2)/(np.exp(1) - 1)\n",
    "    M = 2*np.exp(1)/(np.exp(1) - 1)\n",
    "    g_density = 1\n",
    "    samples = []\n",
    "    while (len(samples) < n_samples):\n",
    "        x = rng.random()\n",
    "        U = rng.random()\n",
    "        if (U <= f(x)/(g_density*M)):\n",
    "            samples.append(x)\n",
    "\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "samples = problem1_inversion(10)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86215629 0.24926057 0.63452671 ... 0.78410626 0.91436672 0.72902298]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 2\n",
    "\n",
    "\n",
    "problem1_samples = problem1_inversion(100000)\n",
    "print(problem1_samples)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples = problem1_inversion(100000)\n",
    "\n",
    "plt.hist(samples, bins=50, density=True, alpha=1)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Histogram of samples from F(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "problem1_integral = np.mean(np.sin(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "n = len(samples)\n",
    "a = 0\n",
    "b = np.sin(1)\n",
    "delta = 1 - 0.95\n",
    "epsilon = (b - a) * np.sqrt((np.log(2/delta)/(2*n))) # Formula for Hoefdings conf int if \n",
    "\n",
    "\n",
    "problem1_interval = [problem1_integral - epsilon, problem1_integral + epsilon]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04886281 0.04698622 0.04649059 0.04722986 0.04887791 0.04864135\n",
      " 0.04847464 0.04670148 0.04395573 0.04856522]\n"
     ]
    }
   ],
   "source": [
    "# Part 5\n",
    "# import numpy as np\n",
    "# from scipy.optimize import minimize\n",
    "\n",
    "# def f(x):\n",
    "#     return -(20*(x[0]+1)*np.exp(20-(1/x[0])))/x[0]  # x[0] because x is an array\n",
    "\n",
    "# parameter_bounding = [(0, 1/20)]  # bounds as a list of tuples\n",
    "# initial_argument = np.array([1/10])  # starting point\n",
    "\n",
    "# result = minimize(f, initial_argument, bounds=parameter_bounding, method='L-BFGS-B')\n",
    "\n",
    "# print(result)\n",
    "\n",
    "def problem1_inversion_2(n_samples=1):\n",
    "    # Distribution from part 2\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "\n",
    "    # Return a numpy array of length n_samples\n",
    "    \n",
    "    def f(x): # Target density (the derivative of F(x))\n",
    "        if x <= 0 or x >= 1/20:\n",
    "            return 0\n",
    "        else:\n",
    "            # 20xe^(20-(1/x))\n",
    "            #Deriverar med hj채lp av kedjeregeln och f책r\n",
    "            # (20(x+1)e^(20-(1/x)))/x\n",
    "            return (20*(x+1)*np.exp(20-(1/x)))/x\n",
    "        \n",
    "    M = 420.0\n",
    "    g_density = 20\n",
    "\n",
    "\n",
    "    samples = []\n",
    "    while (len(samples) < n_samples):\n",
    "        x = rng.uniform(0, 1/20)\n",
    "        U = rng.random()\n",
    "        if (U <= f(x)/(g_density*M)):\n",
    "            samples.append(x)\n",
    "\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "samples = problem1_inversion_2(10)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem1_inversion returns a numpy array\n",
      "Good, your problem1_samples is a numpy array\n",
      "Good, your problem1_integral is a float\n",
      "Good, your problem1_interval is a tuple or list of length 2\n",
      "Good, your problem1_inversion_2 returns a numpy array\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion_2(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem2_X` which has shape (n_emails,3) where each feature in `problem2_X` corresponds to $X_1,X_2,X_3$ from above, `problem2_Y` which has shape **(n_emails,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [4p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [4p] Train the model `problem2_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem2_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem2_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem2_calibrator`.\n",
    "\n",
    "4. [3p] Use the trained model `problem2_ps` and the calibrator `problem2_calibrator` to make final predictions on the testing data, store the prediction in `problem2_final_predictions`. Compute the $0-1$ test-loss and store it in `problem2_01_loss` and provide a $99\\%$ confidence interval of it, store this in the variable `problem2_interval`, this should again be a tuple as in **problem1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [1 0 1]\n",
      " ...\n",
      " [0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]]\n",
      "(2228, 3) (1115, 3) (2229, 3) (2228,) (1115,) (2229,)\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "\n",
    "from Utils import load_sms, train_test_validation\n",
    "\n",
    "\n",
    "def load_sms():\n",
    "    \"\"\"\n",
    "    A wrapper function to load the sms data\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    lines = []\n",
    "    hamspam = {'ham': 0, 'spam': 1}\n",
    "    \n",
    "    def map_presence_of_word(str, word):\n",
    "        if word.lower() in str.lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    with open('data/spam.csv', mode='r',encoding='latin-1') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # When using the csv reader, each time you use the function\n",
    "        # next on it, it will spit out a list split at the ','\n",
    "        header = next(reader)\n",
    "        # We store this as (\"txt\",label), where we have used the function\n",
    "        # hamspam to convert from \"ham\",\"spam\" to 0 and 1.\n",
    "        data = [[map_presence_of_word(line[1], \"free\"), map_presence_of_word(line[1], \"prize\"), map_presence_of_word(line[1], \"win\"), hamspam[line[0]]] for line in reader]\n",
    "    return data\n",
    "\n",
    "data = load_sms()\n",
    "\n",
    "Y = []\n",
    "for line in data:\n",
    "    Y.append(line.pop())\n",
    "\n",
    "\n",
    "X = np.array(data)\n",
    "Y = np.array(Y)\n",
    "print(X)\n",
    "\n",
    "X_train, X_test, X_valid, Y_train, Y_test, Y_valid = train_test_validation(X,Y,test_size=0.4,validation_size=0.2,random_state=42,shuffle=True)\n",
    "\n",
    "\n",
    "problem2_X = X\n",
    "problem2_Y = Y\n",
    "\n",
    "problem2_X_calib = X_valid\n",
    "problem2_X_train = X_train\n",
    "problem2_X_test = X_test\n",
    "problem2_Y_train = Y_train\n",
    "problem2_Y_calib = Y_valid\n",
    "problem2_Y_test = Y_test\n",
    "\n",
    "print(problem2_X_train.shape,problem2_X_calib.shape,problem2_X_test.shape,problem2_Y_train.shape,problem2_Y_calib.shape,problem2_Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        beta_0 = coeffs[0]\n",
    "        beta_1 = coeffs[1:]\n",
    "        \n",
    "        Z = 2*Y - 1\n",
    "        linear_combination = beta_0 + np.dot(X, beta_1)\n",
    "        \n",
    "        loss = np.mean(np.log(1 + np.exp((-Z) * (linear_combination))))\n",
    "        return loss\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        #Use the f above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "            return np.round(10*G(np.dot(X,self.coeffs[1:])+self.coeffs[0]))/10 # This rounding is to help you with the calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115,)\n",
      "(1115,)\n"
     ]
    }
   ],
   "source": [
    "# Part 3\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = ProportionalSpam()\n",
    "problem2_ps = model.fit(X=X_train, Y=Y_train)\n",
    "\n",
    "problem2_X_pred = model.predict(X_valid)\n",
    "\n",
    "print(Y_valid.shape)\n",
    "print(problem2_X_pred.shape)\n",
    "problem2_calibrator = model.fit(X=X_valid, Y=problem2_X_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# These are the predicted probabilities\n",
    "problem2_final_predictions = XXX\n",
    "\n",
    "\n",
    "# In order to compute this loss we first need to convert the predicted probabilities to a decision\n",
    "# recall the Bayes classifier?\n",
    "problem2_01_loss = XXX\n",
    "\n",
    "# Recall the interval is given as a tuple (a,b) or a list [a,b]\n",
    "problem2_interval = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was correct for a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Consider the following four Markov chains, answer each question for all chains:\n",
    "\n",
    "<img width=\"400px\" src=\"pictures/MarkovA.png\">Markov chain A</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovB.png\">Markov chain B</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovC.png\">Markov chain C</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovD.png\">Markov chain D</img>\n",
    "\n",
    "1. [2p] What is the transition matrix?\n",
    "2. [2p] Is the Markov chain irreducible?\n",
    "3. [3p] Is the Markov chain aperiodic? What is the period for each state?\n",
    "4. [3p] Does the Markov chain have a stationary distribution, and if so, what is it?\n",
    "5. [3p] Is the Markov chain reversible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 1\n",
    "\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "\n",
    "problem3_A    = XXX\n",
    "problem3_B    = XXX\n",
    "problem3_C    = XXX\n",
    "problem3_D    = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "problem3_A_irreducible = XXX\n",
    "problem3_B_irreducible = XXX\n",
    "problem3_C_irreducible = XXX\n",
    "problem3_D_irreducible = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "problem3_A_is_aperiodic = XXX\n",
    "problem3_B_is_aperiodic = XXX\n",
    "problem3_C_is_aperiodic = XXX\n",
    "problem3_D_is_aperiodic = XXX\n",
    "\n",
    "# Answer the following with the period of the states as a numpy array\n",
    "# of shape (n_states,)\n",
    "\n",
    "problem3_A_periods = XXX\n",
    "problem3_B_periods = XXX\n",
    "problem3_C_periods = XXX\n",
    "problem3_D_periods = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 4\n",
    "#------------------------STATIONARY DISTRIBUTION-----------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "problem3_A_has_stationary = XXX\n",
    "problem3_B_has_stationary = XXX\n",
    "problem3_C_has_stationary = XXX\n",
    "problem3_D_has_stationary = XXX\n",
    "\n",
    "# Answer the following with the stationary distribution as a numpy array of shape (n_states,)\n",
    "# if the Markov chain has a stationary distribution otherwise answer with False\n",
    "\n",
    "problem3_A_stationary_dist = XXX\n",
    "problem3_B_stationary_dist = XXX\n",
    "problem3_C_stationary_dist = XXX\n",
    "problem3_D_stationary_dist = XXX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 5\n",
    "#------------------------REVERSIBLE-----------------\n",
    "# Answer each one with a True or False\n",
    "\n",
    "problem3_A_is_reversible = XXX\n",
    "problem3_B_is_reversible = XXX\n",
    "problem3_C_is_reversible = XXX\n",
    "problem3_D_is_reversible = XXX"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
